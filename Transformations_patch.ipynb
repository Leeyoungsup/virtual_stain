{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import slideio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transfer_df=pd.read_csv('../../data/100x_Transfer.csv')\n",
    "HE_svs_path='../../data/svs/HE/'\n",
    "stain_svs_path='../../data/svs/'\n",
    "tile_path= '../../data/tiles_2/'\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "        \n",
    "def rotate_and_translate_coordinates(coords, angle_degrees, translation_x, translation_y, image_width, image_height):\n",
    "    # 각도를 라디안으로 변환\n",
    "    angle_rad = np.radians(angle_degrees)\n",
    "  \n",
    "    # 이미지 중심으로 이동\n",
    "    coords_centered = coords - np.array([image_width / 2, image_height / 2])\n",
    "    \n",
    "    # 회전 행렬 구성\n",
    "    rotation_matrix = np.array([[np.cos(angle_rad), -np.sin(angle_rad)],\n",
    "                               [np.sin(angle_rad), np.cos(angle_rad)]])\n",
    "    # 이동\n",
    "    rotated_and_translated_coordinates = coords_centered + np.array([translation_x, translation_y])\n",
    "    \n",
    "    # 좌표 회전\n",
    "    rotated_coordinates = np.dot(rotated_and_translated_coordinates, rotation_matrix.T)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 다시 이미지 중심으로 이동\n",
    "    rotated_coordinates += np.array([image_width / 2, image_height / 2])\n",
    "    \n",
    "    return rotated_coordinates\n",
    "\n",
    "def rotate(xy, angle):\n",
    "    x, y = xy\n",
    "    x = x - 512\n",
    "    y = y - 512\n",
    "    rad = np.deg2rad(angle)\n",
    "    x1 = x * np.cos(rad) - y * np.sin(rad)\n",
    "    y1 = x * np.sin(rad) + y * np.cos(rad)\n",
    "    x1 = x1 + 512\n",
    "    y1 = y1 + 512\n",
    "    x1=x1-x1.min()\n",
    "    y1=y1-y1.min()\n",
    "    x1=x1/x1.max()*1023\n",
    "    y1=y1/y1.max()*1023\n",
    "    x1=x1.astype(int)\n",
    "    y1=y1.astype(int)\n",
    "    return x1, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefb5079e23b44ffb80e9339ba5f2481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JPEGFixupTagsSubsamplingSec: Warning, Auto-corrected former TIFF subsampling values [2,2] to match subsampling values inside JPEG compressed data [2,1].\n",
      "JPEGFixupTagsSubsamplingSec: Warning, Auto-corrected former TIFF subsampling values [2,2] to match subsampling values inside JPEG compressed data [2,1].\n",
      "JPEGFixupTagsSubsamplingSec: Warning, Auto-corrected former TIFF subsampling values [2,2] to match subsampling values inside JPEG compressed data [2,1].\n",
      "JPEGFixupTagsSubsamplingSec: Warning, Auto-corrected former TIFF subsampling values [2,2] to match subsampling values inside JPEG compressed data [2,1].\n",
      "JPEGFixupTagsSubsamplingSec: Warning, Auto-corrected former TIFF subsampling values [2,2] to match subsampling values inside JPEG compressed data [2,1].\n",
      "JPEGFixupTagsSubsamplingSec: Warning, Auto-corrected former TIFF subsampling values [2,2] to match subsampling values inside JPEG compressed data [2,1].\n",
      "JPEGFixupTagsSubsamplingSec: Warning, Auto-corrected former TIFF subsampling values [2,2] to match subsampling values inside JPEG compressed data [2,1].\n",
      "JPEGFixupTagsSubsamplingSec: Warning, Auto-corrected former TIFF subsampling values [2,2] to match subsampling values inside JPEG compressed data [2,1].\n",
      "JPEGFixupTagsSubsamplingSec: Warning, Auto-corrected former TIFF subsampling values [2,2] to match subsampling values inside JPEG compressed data [2,1].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m rectangle_coordinates \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[widthCount \u001b[38;5;241m*\u001b[39m slide_tile_size,heightCount \u001b[38;5;241m*\u001b[39m slide_tile_size], [widthCount \u001b[38;5;241m*\u001b[39m slide_tile_size\u001b[38;5;241m+\u001b[39mslide_tile_size, heightCount \u001b[38;5;241m*\u001b[39m slide_tile_size], [widthCount \u001b[38;5;241m*\u001b[39m slide_tile_size, heightCount \u001b[38;5;241m*\u001b[39m slide_tile_size\u001b[38;5;241m+\u001b[39mslide_tile_size], [widthCount \u001b[38;5;241m*\u001b[39m slide_tile_size\u001b[38;5;241m+\u001b[39mslide_tile_size, heightCount \u001b[38;5;241m*\u001b[39m slide_tile_size\u001b[38;5;241m+\u001b[39mslide_tile_size]])\n\u001b[1;32m     40\u001b[0m result \u001b[38;5;241m=\u001b[39m rotate_and_translate_coordinates(rectangle_coordinates, angle, \u001b[38;5;241m-\u001b[39mx, \u001b[38;5;241m-\u001b[39my, stain_svsWidth, stain_svsHeight)\n\u001b[0;32m---> 41\u001b[0m stain_slide_block \u001b[38;5;241m=\u001b[39m \u001b[43mstain_scene\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m he_32x_img\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mfromarray(he_slide_block)\u001b[38;5;241m.\u001b[39mresize((save_image_size,save_image_size))\n\u001b[1;32m     43\u001b[0m (cX, cY) \u001b[38;5;241m=\u001b[39m (image_size, image_size)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/slideio/py_slideio.py:145\u001b[0m, in \u001b[0;36mScene.read_block\u001b[0;34m(self, rect, size, channel_indices, slices, frames)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, rect\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m), size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m), channel_indices\u001b[38;5;241m=\u001b[39m[], slices\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m), frames\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Reads rectangular block of the scene with optional rescaling.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m        numpy array with pixel values\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscene\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_size=512\n",
    "save_image_size=256\n",
    "slide_tile_size=4096\n",
    "for i in tqdm(range(len(Transfer_df))):\n",
    "    fileName=Transfer_df.loc[i]['slide']\n",
    "    stain=Transfer_df.loc[i]['stain']\n",
    "    x=Transfer_df.loc[i]['x']*100\n",
    "    y=Transfer_df.loc[i]['y']*100\n",
    "    angle=Transfer_df.loc[i]['angle']\n",
    "    he_slide = slideio.open_slide(HE_svs_path+fileName+'.svs', \"SVS\")\n",
    "    stain_slide = slideio.open_slide(stain_svs_path+stain+'/'+fileName+'.svs', \"SVS\")\n",
    "    he_scene = he_slide.get_scene(0)\n",
    "    stain_scene = stain_slide.get_scene(0)\n",
    "    he_svsWidth = he_scene.rect[2]\n",
    "    he_svsHeight = he_scene.rect[3]\n",
    "    stain_svsWidth = stain_scene.rect[2]\n",
    "    stain_svsHeight = stain_scene.rect[3]\n",
    "    inverse_Height_ratio=he_mask.shape[0]/he_svsHeight\n",
    "    inverse_Width_ratio=he_mask.shape[1]/he_svsWidth\n",
    "    he_thumbnali_block = he_scene.read_block((0, 0, he_svsWidth, he_svsHeight),size=(he_svsWidth//100, he_svsHeight//100))\n",
    "    he_mask=cv2.threshold(cv2.cvtColor(he_thumbnali_block,cv2.COLOR_RGB2HSV)[:,:,1], 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "    he_mask=cv2.morphologyEx(he_mask, cv2.MORPH_CLOSE, k)\n",
    "    createDirectory(tile_path+stain+'/'+fileName+'/stain/')\n",
    "    createDirectory(tile_path+stain+'/'+fileName+'/he/')\n",
    "    for widthCount in range(0, int(he_svsWidth // slide_tile_size)):\n",
    "        for heightCount in range(0, int(he_svsHeight // slide_tile_size)):\n",
    "            point_x =int(widthCount*slide_tile_size*inverse_Width_ratio)\n",
    "            point_y =int(heightCount*slide_tile_size*inverse_Height_ratio)\n",
    "            tile_hw=int(slide_tile_size*inverse_Height_ratio)\n",
    "            if (point_x+tile_hw)>=he_mask.shape[1]:\n",
    "                point_x=he_mask.shape[1]-tile_hw-1\n",
    "            if (point_y+tile_hw)>=he_mask.shape[0]:\n",
    "                point_y=he_mask.shape[0]-tile_hw-1\n",
    "            tile_mask_image=he_mask[point_y:point_y+tile_hw,point_x:point_x+tile_hw]/255\n",
    "            if tile_mask_image.mean()>0.2:\n",
    "                he_slide_block = he_scene.read_block((widthCount * slide_tile_size, heightCount * slide_tile_size, slide_tile_size, slide_tile_size),size=(image_size, image_size))\n",
    "                \n",
    "                rectangle_coordinates = np.array([[widthCount * slide_tile_size,heightCount * slide_tile_size], [widthCount * slide_tile_size+slide_tile_size, heightCount * slide_tile_size], [widthCount * slide_tile_size, heightCount * slide_tile_size+slide_tile_size], [widthCount * slide_tile_size+slide_tile_size, heightCount * slide_tile_size+slide_tile_size]])\n",
    "                result = rotate_and_translate_coordinates(rectangle_coordinates, angle, -x, -y, stain_svsWidth, stain_svsHeight)\n",
    "                stain_slide_block = stain_scene.read_block((int(result[:,0].min()), int(result[:,1].min()), int(result[:,0].max())-int(result[:,0].min()), int(result[:,1].max())-int(result[:,1].min())),size=(image_size*2, image_size*2))\n",
    "                he_32x_img=Image.fromarray(he_slide_block).resize((save_image_size,save_image_size))\n",
    "                (cX, cY) = (image_size, image_size)\n",
    "                M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "                # stain_slide_block = cv2.warpAffine(stain_slide_block, M, (image_size*2, image_size*2))\n",
    "                mesh_x = np.linspace(0, image_size*2-1, image_size*2,dtype=np.int32)\n",
    "                mesh_y = np.linspace(0, image_size*2-1,  image_size*2,dtype=np.int32)\n",
    "                mesh_xy = np.meshgrid(mesh_x, mesh_y)\n",
    "                mesh_xy = rotate(mesh_xy, angle)\n",
    "                stain_slide_block=stain_slide_block[mesh_xy[1],mesh_xy[0]]\n",
    "                stain_32x_img=Image.fromarray(stain_slide_block).resize((save_image_size,save_image_size))\n",
    "                he_32x_img.save(tile_path+stain+'/'+fileName+'/he/'+str(widthCount * slide_tile_size)+'_'+str(heightCount * slide_tile_size)+'.jpg')\n",
    "                stain_32x_img.save(tile_path+stain+'/'+fileName+'/stain/'+str(widthCount * slide_tile_size)+'_'+str(heightCount * slide_tile_size)+'.jpg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
